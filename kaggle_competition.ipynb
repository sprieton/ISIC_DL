{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025 Kaggle Competition of AI Applied to Medicine at UC3M\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Welcome to the **2025 Kaggle competition of AI applied to medicine at UC3M**. This project is set up as an **internal Kaggle competition** in which all students will participate. Our real-world challenge for this course will revolve around the **ISIC 2024** dataset, a large collection of skin images used for research in dermatology.\n",
    "\n",
    "\n",
    "Welcome to our simple **ResNet50-based** starter notebook. Below we:\n",
    "1. **Define** a function to load images from HDF5 files.\n",
    "2. **Load** and display our training metadata (no preprocessing).\n",
    "3. **Load** a pretrained **ResNet50** model (we won't fine-tune it).\n",
    "4. **Evaluate** test samples (in a trivial way for demonstration).\n",
    "5. **Generate** a simple `submission.csv` file with the required format.\n",
    "\n",
    "> **Note**: This is a minimal example to help you set up your environment. It doesn’t include any real training or meaningful model inference. Feel free to modify it to perform actual classification (e.g., add custom layers, train on your dataset, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISIC 2024 Competition Overview\n",
    "\n",
    "The **International Skin Imaging Collaboration (ISIC)** has launched this competition to advance automated skin cancer detection by:\n",
    "- **Improving accuracy** in distinguishing malignant from benign lesions  \n",
    "- **Enhancing efficiency** in clinical workflows  \n",
    "- **Developing algorithms** that prioritize high-risk lesions  \n",
    "- **Reducing mortality rates** by enabling earlier detection  \n",
    "\n",
    "### Primary Task\n",
    "You need to **classify skin lesions** as **benign** or **malignant**. For each lesion image (identified by `isic_id`), predict a **probability** in the range [0, 1] indicating the chance that the lesion is malignant.\n",
    "\n",
    "### High-Level Data Summary\n",
    "- The dataset is called **SLICE-3D**, containing **skin lesion images** (JPEG files) cropped from 3D Total Body Photography (TBP).  \n",
    "- Each image has metadata in a corresponding `.csv` file, including:  \n",
    "  - **Binary diagnostic label** (`target` = 0 or 1)  \n",
    "  - **Patient data** (e.g., `age_approx`, `sex`, `anatom_site_general`)  \n",
    "  - **Additional attributes** (image source, diagnosis type)\n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4972760%2F349a3ae1149d15dc5642063a2d742c88%2Fimage%20type_noexif_240425.jpg?generation=1714060307710359&alt=media)\n",
    "\n",
    "This challenge dataset mimics **non-dermoscopic images** using standardized 15x15 mm “tiles” of lesions from a 3D TBP system. Thousands of patients from multiple continents are represented, creating a broad, diverse dataset.\n",
    "\n",
    "### Task Description & Clinical Context\n",
    "- **Why it matters**: Skin cancer can be deadly if not detected early. Many people lack access to dermatologic care, so accurate AI systems for image-based triage can improve outcomes.  \n",
    "- **Key goal**: Develop a binary classifier that identifies malignant lesions from a set of smartphone-quality images.  \n",
    "- **Impact**: This technology could help prioritize suspicious lesions (top K) for clinical review, especially in low-resource settings, potentially **saving lives** through earlier detection.\n",
    "\n",
    "### Importance of 3D TBP\n",
    "The **3D Total Body Photography (TBP)** approach captures the entire skin surface in macro resolution. Each lesion on the patient’s body is automatically cropped as a 15x15 mm image tile. These images more closely resemble photos taken by a regular smartphone camera, as opposed to specialized dermoscopy devices.\n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4972760%2F169b1f691322233e7b31aabaf6716ff3%2Fex-tiles.png?generation=1717700538524806&alt=media)\n",
    "\n",
    "### Clinical Background\n",
    "1. **Major skin cancer types**: Basal Cell Carcinoma (BCC), Squamous Cell Carcinoma (SCC), and Melanoma (most lethal).  \n",
    "2. **Early detection** is crucial: Minor surgery can cure many skin cancers if caught in time.  \n",
    "3. **Telemedicine implications**: With the rise in remote healthcare, patients often submit low-quality images captured at home. Robust AI models are needed to handle this variability.\n",
    "\n",
    "### Summary\n",
    "- You will build a model to **classify skin lesions** (benign vs. malignant) with probabilities.  \n",
    "- The dataset includes **every lesion** from thousands of patients, reflecting real-world diversity.  \n",
    "- **3D TBP** and the “ugly duckling sign” concept illustrate the importance of comparing each lesion against the patient’s total lesion landscape.  \n",
    "- **Your work** can help improve early detection, prioritizing high-risk cases for clinical evaluation and potentially saving lives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_COL2DESC = {\n",
    "    \"isic_id\": \"Unique identifier for each image case.\",\n",
    "    \"target\": \"Binary class label (0 = benign, 1 = malignant).\",\n",
    "    \"patient_id\": \"Unique identifier for each patient.\",\n",
    "    \"age_approx\": \"Approximate age of the patient at time of imaging.\",\n",
    "    \"sex\": \"Sex of the patient (male or female).\",\n",
    "    \"anatom_site_general\": \"General location of the lesion on the patient's body.\",\n",
    "    \"clin_size_long_diam_mm\": \"Maximum diameter of the lesion (mm).\",\n",
    "    \"image_type\": \"Type of image captured, as defined in the ISIC Archive.\",\n",
    "    \"tbp_tile_type\": \"Lighting modality of the 3D Total Body Photography (TBP) source image.\",\n",
    "    \"tbp_lv_A\": \"Color channel A (green-red axis in LAB space) inside the lesion.\",\n",
    "    \"tbp_lv_Aext\": \"Color channel A outside the lesion.\",\n",
    "    \"tbp_lv_B\": \"Color channel B (blue-yellow axis in LAB space) inside the lesion.\",\n",
    "    \"tbp_lv_Bext\": \"Color channel B outside the lesion.\",\n",
    "    \"tbp_lv_C\": \"Chroma value inside the lesion.\",\n",
    "    \"tbp_lv_Cext\": \"Chroma value outside the lesion.\",\n",
    "    \"tbp_lv_H\": \"Hue value inside the lesion (LAB color space).\",\n",
    "    \"tbp_lv_Hext\": \"Hue value outside the lesion.\",\n",
    "    \"tbp_lv_L\": \"Luminance inside the lesion (LAB color space).\",\n",
    "    \"tbp_lv_Lext\": \"Luminance outside the lesion.\",\n",
    "    \"tbp_lv_areaMM2\": \"Area of the lesion in mm².\",\n",
    "    \"tbp_lv_area_perim_ratio\": \"Ratio of the lesion's perimeter to its area (border jaggedness).\",\n",
    "    \"tbp_lv_color_std_mean\": \"Mean color irregularity within the lesion.\",\n",
    "    \"tbp_lv_deltaA\": \"Average contrast in color channel A between inside and outside.\",\n",
    "    \"tbp_lv_deltaB\": \"Average contrast in color channel B between inside and outside.\",\n",
    "    \"tbp_lv_deltaL\": \"Average contrast in luminance between inside and outside.\",\n",
    "    \"tbp_lv_deltaLB\": \"Combined contrast between the lesion and surrounding skin.\",\n",
    "    \"tbp_lv_deltaLBnorm\": \"Normalized contrast (LAB color space).\",\n",
    "    \"tbp_lv_eccentricity\": \"Eccentricity of the lesion (how elongated it is).\",\n",
    "    \"tbp_lv_location\": \"Detailed anatomical location (e.g., Upper Arm).\",\n",
    "    \"tbp_lv_location_simple\": \"Simplified anatomical location (e.g., Arm).\",\n",
    "    \"tbp_lv_minorAxisMM\": \"Smallest diameter of the lesion in mm.\",\n",
    "    \"tbp_lv_nevi_confidence\": \"Confidence score (0-100) for the lesion being a nevus.\",\n",
    "    \"tbp_lv_norm_border\": \"Normalized border irregularity (0-10 scale).\",\n",
    "    \"tbp_lv_norm_color\": \"Normalized color variation (0-10 scale).\",\n",
    "    \"tbp_lv_perimeterMM\": \"Perimeter of the lesion in mm.\",\n",
    "    \"tbp_lv_radial_color_std_max\": \"Color asymmetry within the lesion, measured radially.\",\n",
    "    \"tbp_lv_stdL\": \"Std. deviation of luminance inside the lesion.\",\n",
    "    \"tbp_lv_stdLExt\": \"Std. deviation of luminance outside the lesion.\",\n",
    "    \"tbp_lv_symm_2axis\": \"Asymmetry about a second axis of symmetry.\",\n",
    "    \"tbp_lv_symm_2axis_angle\": \"Angle of that second axis of symmetry.\",\n",
    "    \"tbp_lv_x\": \"X-coordinate in the 3D TBP model.\",\n",
    "    \"tbp_lv_y\": \"Y-coordinate in the 3D TBP model.\",\n",
    "    \"tbp_lv_z\": \"Z-coordinate in the 3D TBP model.\",\n",
    "    \"attribution\": \"Image source or institution.\",\n",
    "    \"copyright_license\": \"License information.\",\n",
    "    \"lesion_id\": \"Unique ID for lesions of interest.\",\n",
    "    \"iddx_full\": \"Full diagnosis classification.\",\n",
    "    \"iddx_1\": \"First-level (broad) diagnosis.\",\n",
    "    \"iddx_2\": \"Second-level diagnosis.\",\n",
    "    \"iddx_3\": \"Third-level diagnosis.\",\n",
    "    \"iddx_4\": \"Fourth-level diagnosis.\",\n",
    "    \"iddx_5\": \"Fifth-level diagnosis.\",\n",
    "    \"mel_mitotic_index\": \"Mitotic index of invasive malignant melanomas.\",\n",
    "    \"mel_thick_mm\": \"Thickness of melanoma invasion in mm.\",\n",
    "    \"tbp_lv_dnn_lesion_confidence\": \"Lesion confidence score (0-100) from a DNN classifier.\"\n",
    "}\n",
    "\n",
    "METADATA_COL2NAME = {\n",
    "    \"isic_id\": \"Unique Case Identifier\",\n",
    "    \"target\": \"Binary Lesion Classification\",\n",
    "    \"patient_id\": \"Unique Patient Identifier\",\n",
    "    \"age_approx\": \"Approximate Age\",\n",
    "    \"sex\": \"Sex\",\n",
    "    \"anatom_site_general\": \"General Anatomical Location\",\n",
    "    \"clin_size_long_diam_mm\": \"Clinical Size (Longest Diameter in mm)\",\n",
    "    \"image_type\": \"Image Type\",\n",
    "    \"tbp_tile_type\": \"TBP Tile Type\",\n",
    "    \"tbp_lv_A\": \"Color Channel A (Inside)\",\n",
    "    \"tbp_lv_Aext\": \"Color Channel A (Outside)\",\n",
    "    \"tbp_lv_B\": \"Color Channel B (Inside)\",\n",
    "    \"tbp_lv_Bext\": \"Color Channel B (Outside)\",\n",
    "    \"tbp_lv_C\": \"Chroma (Inside)\",\n",
    "    \"tbp_lv_Cext\": \"Chroma (Outside)\",\n",
    "    \"tbp_lv_H\": \"Hue (Inside)\",\n",
    "    \"tbp_lv_Hext\": \"Hue (Outside)\",\n",
    "    \"tbp_lv_L\": \"Luminance (Inside)\",\n",
    "    \"tbp_lv_Lext\": \"Luminance (Outside)\",\n",
    "    \"tbp_lv_areaMM2\": \"Lesion Area (mm²)\",\n",
    "    \"tbp_lv_area_perim_ratio\": \"Area-to-Perimeter Ratio\",\n",
    "    \"tbp_lv_color_std_mean\": \"Mean Color Irregularity\",\n",
    "    \"tbp_lv_deltaA\": \"Delta A\",\n",
    "    \"tbp_lv_deltaB\": \"Delta B\",\n",
    "    \"tbp_lv_deltaL\": \"Delta L\",\n",
    "    \"tbp_lv_deltaLB\": \"Delta LB\",\n",
    "    \"tbp_lv_deltaLBnorm\": \"Normalized Delta LB\",\n",
    "    \"tbp_lv_eccentricity\": \"Eccentricity\",\n",
    "    \"tbp_lv_location\": \"Detailed Location\",\n",
    "    \"tbp_lv_location_simple\": \"Simplified Location\",\n",
    "    \"tbp_lv_minorAxisMM\": \"Smallest Diameter (mm)\",\n",
    "    \"tbp_lv_nevi_confidence\": \"Nevus Confidence Score\",\n",
    "    \"tbp_lv_norm_border\": \"Normalized Border Irregularity\",\n",
    "    \"tbp_lv_norm_color\": \"Normalized Color Variation\",\n",
    "    \"tbp_lv_perimeterMM\": \"Lesion Perimeter (mm)\",\n",
    "    \"tbp_lv_radial_color_std_max\": \"Radial Color Deviation\",\n",
    "    \"tbp_lv_stdL\": \"Std. Dev. Luminance (Inside)\",\n",
    "    \"tbp_lv_stdLExt\": \"Std. Dev. Luminance (Outside)\",\n",
    "    \"tbp_lv_symm_2axis\": \"Symmetry (Second Axis)\",\n",
    "    \"tbp_lv_symm_2axis_angle\": \"Symmetry Angle (Second Axis)\",\n",
    "    \"tbp_lv_x\": \"X-Coordinate\",\n",
    "    \"tbp_lv_y\": \"Y-Coordinate\",\n",
    "    \"tbp_lv_z\": \"Z-Coordinate\",\n",
    "    \"attribution\": \"Image Source\",\n",
    "    \"copyright_license\": \"Copyright\",\n",
    "    \"lesion_id\": \"Unique Lesion ID\",\n",
    "    \"iddx_full\": \"Full Diagnosis\",\n",
    "    \"iddx_1\": \"Diagnosis Level 1\",\n",
    "    \"iddx_2\": \"Diagnosis Level 2\",\n",
    "    \"iddx_3\": \"Diagnosis Level 3\",\n",
    "    \"iddx_4\": \"Diagnosis Level 4\",\n",
    "    \"iddx_5\": \"Diagnosis Level 5\",\n",
    "    \"mel_mitotic_index\": \"Mitotic Index (Melanoma)\",\n",
    "    \"mel_thick_mm\": \"Melanoma Thickness (mm)\",\n",
    "    \"tbp_lv_dnn_lesion_confidence\": \"Lesion DNN Confidence\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-59af967f36a3>:93: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(TRAIN_METADATA_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape: (400959, 55)\n",
      "test_df shape:  (100, 44)\n",
      "Train samples: 320767, Valid samples: 80192\n",
      "Created train/valid/test datasets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import models\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# If using GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Custom Dataset for HDF5\n",
    "# ---------------------------\n",
    "class ISIC_HDF5_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that loads images from an HDF5 file given a DataFrame of IDs.\n",
    "    Applies image transforms suitable for ResNet50.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, hdf5_path: str, transform=None, is_labelled: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing 'isic_id' and optionally 'target'.\n",
    "            hdf5_path (str): Path to the HDF5 file containing images.\n",
    "            transform (callable): Optional transforms to be applied on a sample.\n",
    "            is_labelled (bool): Whether the dataset includes labels (for train/val).\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.transform = transform\n",
    "        self.is_labelled = is_labelled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        isic_id = row[\"isic_id\"]\n",
    "        \n",
    "        # Load image from HDF5\n",
    "        image_rgb = self._load_image_from_hdf5(isic_id)\n",
    "        \n",
    "        # Apply transforms (PIL-style transforms require converting np array to PIL, or we can do tensor transforms)\n",
    "        if self.transform is not None:\n",
    "            # Convert NumPy array (H x W x C) to a PIL Image\n",
    "            import torchvision.transforms.functional as F_v\n",
    "            image_pil = F_v.to_pil_image(image_rgb)\n",
    "            image = self.transform(image_pil)\n",
    "        else:\n",
    "            # By default, convert it to a tensor (C x H x W)\n",
    "            image = torch.from_numpy(image_rgb).permute(2, 0, 1).float()\n",
    "\n",
    "        if self.is_labelled:\n",
    "            label = row[\"target\"]\n",
    "            label = torch.tensor(label).float()\n",
    "            return image, label, isic_id\n",
    "        else:\n",
    "            return image, isic_id\n",
    "\n",
    "    def _load_image_from_hdf5(self, isic_id: str):\n",
    "        \"\"\"\n",
    "        Loads and decodes an image from HDF5 by isic_id.\n",
    "        Returns a NumPy array in RGB format (H x W x 3).\n",
    "        \"\"\"\n",
    "        with h5py.File(self.hdf5_path, 'r') as hf:\n",
    "            encoded_bytes = hf[isic_id][()]  # uint8 array\n",
    "\n",
    "        # Decode the image bytes with OpenCV (returns BGR)\n",
    "        image_bgr = cv2.imdecode(encoded_bytes, cv2.IMREAD_COLOR)\n",
    "        # Convert to RGB\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return image_rgb\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. DataFrames and Basic Preprocessing / Transforms\n",
    "# ----------------------------------------------------\n",
    "# -----------------------------\n",
    "# 3. Data Setup (Train/Valid/Test)\n",
    "# -----------------------------\n",
    "TRAIN_METADATA_CSV = \"data/new-train-metadata.csv\"\n",
    "TEST_METADATA_CSV  = \"data/students-test-metadata.csv\"\n",
    "TRAIN_HDF5         = \"data/train-image.hdf5\"\n",
    "TEST_HDF5          = \"data/test-image.hdf5\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_METADATA_CSV)\n",
    "test_df  = pd.read_csv(TEST_METADATA_CSV)\n",
    "\n",
    "print(f\"train_df shape: {train_df.shape}\")\n",
    "print(f\"test_df shape:  {test_df.shape}\")\n",
    "\n",
    "# Example: split train_df into 80% train / 20% valid\n",
    "train_size = int(0.8 * len(train_df))\n",
    "valid_size = len(train_df) - train_size\n",
    "train_subset, valid_subset = random_split(\n",
    "    train_df, \n",
    "    [train_size, valid_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_df_sub = train_df.iloc[train_subset.indices].reset_index(drop=True)\n",
    "valid_df_sub = train_df.iloc[valid_subset.indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_df_sub)}, Valid samples: {len(valid_df_sub)}\")\n",
    "\n",
    "# Basic transforms for ResNet\n",
    "resnet_transforms = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = ISIC_HDF5_Dataset(\n",
    "    df=train_df_sub, \n",
    "    hdf5_path=TRAIN_HDF5,\n",
    "    transform=resnet_transforms,\n",
    "    is_labelled=True\n",
    ")\n",
    "\n",
    "valid_dataset = ISIC_HDF5_Dataset(\n",
    "    df=valid_df_sub,\n",
    "    hdf5_path=TRAIN_HDF5,\n",
    "    transform=resnet_transforms,\n",
    "    is_labelled=True\n",
    ")\n",
    "\n",
    "test_dataset = ISIC_HDF5_Dataset(\n",
    "    df=test_df,\n",
    "    hdf5_path=TEST_HDF5,\n",
    "    transform=resnet_transforms,\n",
    "    is_labelled=False\n",
    ")\n",
    "\n",
    "print(\"Created train/valid/test datasets.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader: 125 batches (total = 1000 samples / batch_size = 8)\n",
      "Valid loader: 10024 batches\n",
      "Test loader:  13 batches\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. RandomSampler for 1000 Samples per Epoch\n",
    "# -----------------------------\n",
    "# Instead of weighting for class imbalance, we simply draw 1000 random samples each epoch.\n",
    "# Students can discover the imbalance issue themselves!\n",
    "\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "# A RandomSampler with replacement=True can pick num_samples=1000 each epoch\n",
    "sampler = RandomSampler(\n",
    "    data_source=train_dataset,\n",
    "    replacement=True,\n",
    "    num_samples=1000\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,  # No shuffle needed, RandomSampler handles randomness\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches (total = 1000 samples / batch_size = {BATCH_SIZE})\")\n",
    "print(f\"Valid loader: {len(valid_loader)} batches\")\n",
    "print(f\"Test loader:  {len(test_loader)} batches\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/gts_usuarios/alexjorguer/miniconda3/envs/clostridium/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/export/gts_usuarios/alexjorguer/miniconda3/envs/clostridium/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Load & Modify ResNet50 for Binary Classification\n",
    "# -----------------------------\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replace final layer for binary classification\n",
    "model.fc = nn.Linear(in_features=2048, out_features=1)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.0766))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 0.0164))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 0.0015))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.0075))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.0008))\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Training Loop (5 Epochs, Only 1000 Samples/Epoch)\n",
    "# -----------------------------\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images).view(-1)  # [batch_size]\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | Train Loss: {avg_train_loss:.4f}))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on Test:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on Test: 100%|██████████| 13/13 [00:00<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission with 100 rows to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0082829</td>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0114227</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0157465</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0197356</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0275647</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISIC_0332355</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISIC_0528190</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISIC_0576478</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISIC_0719839</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISIC_0968965</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0082829  0.000349\n",
       "1  ISIC_0114227  0.000398\n",
       "2  ISIC_0157465  0.000469\n",
       "3  ISIC_0197356  0.000960\n",
       "4  ISIC_0275647  0.000363\n",
       "5  ISIC_0332355  0.000440\n",
       "6  ISIC_0528190  0.000527\n",
       "7  ISIC_0576478  0.000472\n",
       "8  ISIC_0719839  0.000478\n",
       "9  ISIC_0968965  0.000827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7. Inference on Test Set & Submission\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, isic_ids in tqdm(test_loader, desc=\"Inference on Test\"):\n",
    "        images = images.to(device)\n",
    "        logits = model(images).view(-1)  # shape [batch_size]\n",
    "        probs = torch.sigmoid(logits)    # shape [batch_size], in [0,1]\n",
    "        \n",
    "        probs = probs.cpu().numpy()\n",
    "        \n",
    "        for isic_id, p in zip(isic_ids, probs):\n",
    "            predictions.append({\"isic_id\": isic_id, \"target\": float(p)})\n",
    "\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df = submission_df.sort_values(by=\"isic_id\").reset_index(drop=True)\n",
    "\n",
    "submission_file = \"submission.csv\"\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"Saved submission with {len(submission_df)} rows to {submission_file}\")\n",
    "display(submission_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clostridium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
